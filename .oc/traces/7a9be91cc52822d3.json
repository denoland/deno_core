{
  "id": "bca81775b96c8d36",
  "trigger": "current diff explain",
  "trigger_id": "7a9be91cc52822d3",
  "raw_trigger": "explain the current diff",
  "effects": [
    {
      "tool": "bash",
      "input": {
        "command": "git diff"
      },
      "output": "diff --git a/core/00_infra.js b/core/00_infra.js\nindex c515e29..7907d8a 100644\n--- a/core/00_infra.js\n+++ b/core/00_infra.js\n@@ -40,7 +40,6 @@\n \n   let isLeakTracingEnabled = false;\n   let submitLeakTrace;\n-  let eventLoopTick;\n \n   function __setLeakTracingEnabled(enabled) {\n     isLeakTracingEnabled = enabled;\n@@ -50,8 +49,7 @@\n     return isLeakTracingEnabled;\n   }\n \n-  function __initializeCoreMethods(eventLoopTick_, submitLeakTrace_) {\n-    eventLoopTick = eventLoopTick_;\n+  function __initializeCoreMethods(submitLeakTrace_) {\n     submitLeakTrace = submitLeakTrace_;\n   }\n \n@@ -143,9 +141,9 @@\n     });\n     const wrappedPromise = PromisePrototypeCatch(\n       promise,\n-      (res) =\u003e {\n-        // recreate the stacktrace and strip eventLoopTick() calls from stack trace\n-        ErrorCaptureStackTrace(res, eventLoopTick);\n+      function __opRejectHandler(res) {\n+        // recreate the stacktrace and strip internal event loop frames\n+        ErrorCaptureStackTrace(res, __opRejectHandler);\n         throw res;\n       },\n     );\ndiff --git a/core/01_core.js b/core/01_core.js\nindex fefbccf..bf5a031 100755\n--- a/core/01_core.js\n+++ b/core/01_core.js\n@@ -122,7 +122,6 @@\n   delete window.__infra;\n \n   __initializeCoreMethods(\n-    eventLoopTick,\n     submitLeakTrace,\n   );\n \n@@ -143,8 +142,6 @@\n \n   let unhandledPromiseRejectionHandler = () =\u003e false;\n   let timerDepth = 0;\n-  let timersRunning = false;\n-  const cancelledTimers = new Set();\n \n   const macrotaskCallbacks = [];\n   const nextTickCallbacks = [];\n@@ -162,24 +159,22 @@\n     ArrayPrototypePush(immediateCallbacks, cb);\n   }\n \n-  // This function has variable number of arguments. The last argument describes\n-  // if there's a \"next tick\" scheduled by the Node.js compat layer. Arguments\n-  // before last are alternating integers and any values that describe the\n-  // responses of async ops.\n-  function eventLoopTick() {\n-    let didAnyWork = false;\n-\n-    // First respond to all pending ops.\n-    for (let i = 0; i \u003c arguments.length - 3; i += 3) {\n-      didAnyWork = true;\n+  // Phase 2: Resolve completed async ops. Called from Rust with flat args:\n+  // (promiseId, isOk, res, promiseId, isOk, res, ...)\n+  function __resolveOps() {\n+    for (let i = 0; i \u003c arguments.length; i += 3) {\n       const promiseId = arguments[i];\n       const isOk = arguments[i + 1];\n       const res = arguments[i + 2];\n-\n       __resolvePromise(promiseId, res, isOk);\n     }\n+  }\n+\n+  // Phase 5: Drain nextTick queue and macrotask queue.\n+  // Called from Rust. hasTickScheduled indicates if nextTick was scheduled.\n+  function __drainNextTickAndMacrotasks(hasTickScheduled) {\n     // Drain nextTick queue if there's a tick scheduled.\n-    if (arguments[arguments.length - 1]) {\n+    if (hasTickScheduled) {\n       for (let i = 0; i \u003c nextTickCallbacks.length; i++) {\n         nextTickCallbacks[i]();\n       }\n@@ -187,7 +182,7 @@\n       op_run_microtasks();\n     }\n \n-    // Finally drain macrotask queue.\n+    // Drain macrotask queue.\n     for (let i = 0; i \u003c macrotaskCallbacks.length; i++) {\n       const cb = macrotaskCallbacks[i];\n       while (true) {\n@@ -207,52 +202,31 @@\n         }\n       }\n     }\n+  }\n \n-    const timers = arguments[arguments.length - 2];\n-    if (timers) {\n-      didAnyWork = true;\n-      timersRunning = true;\n-      for (let i = 0; i \u003c timers.length; i += 3) {\n-        timerDepth = timers[i];\n-        const id = timers[i + 1];\n-        if (cancelledTimers.has(id)) {\n-          continue;\n-        }\n-        try {\n-          const f = timers[i + 2];\n-          f.call(window);\n-        } catch (e) {\n-          reportExceptionCallback(e);\n-        }\n-        for (let i = 0; i \u003c nextTickCallbacks.length; i++) {\n-          nextTickCallbacks[i]();\n-        }\n-        op_run_microtasks();\n+  // Phase 2: Handle unhandled promise rejections.\n+  // Called from Rust with a flat array: [promise, reason, promise, reason, ...]\n+  function __handleRejections() {\n+    for (let i = 0; i \u003c arguments.length; i += 2) {\n+      const handled = unhandledPromiseRejectionHandler(\n+        arguments[i],\n+        arguments[i + 1],\n+      );\n+      if (!handled) {\n+        const err = arguments[i + 1];\n+        op_dispatch_exception(err, true);\n       }\n-      timersRunning = false;\n-      timerDepth = 0;\n-      cancelledTimers.clear();\n     }\n+  }\n \n-    // Drain immediates queue.\n-    if (didAnyWork \u0026\u0026 op_immediate_has_ref_count()) {\n-      runImmediateCallbacks();\n-    }\n+  // Set timer depth before each timer callback (called from Rust).\n+  function __setTimerDepth(depth) {\n+    timerDepth = depth;\n+  }\n \n-    // If we have any rejections for this tick, attempt to process them\n-    const rejections = arguments[arguments.length - 3];\n-    if (rejections) {\n-      for (let i = 0; i \u003c rejections.length; i += 2) {\n-        const handled = unhandledPromiseRejectionHandler(\n-          rejections[i],\n-          rejections[i + 1],\n-        );\n-        if (!handled) {\n-          const err = rejections[i + 1];\n-          op_dispatch_exception(err, true);\n-        }\n-      }\n-    }\n+  // Report an exception (called from Rust for timer callback errors).\n+  function __reportException(e) {\n+    reportExceptionCallback(e);\n   }\n \n   function runImmediateCallbacks() {\n@@ -688,7 +662,11 @@\n     internalRidSymbol: Symbol(\"Deno.internal.rid\"),\n     internalFdSymbol: Symbol(\"Deno.internal.fd\"),\n     resources,\n-    eventLoopTick,\n+    __resolveOps,\n+    __drainNextTickAndMacrotasks,\n+    __handleRejections,\n+    __setTimerDepth,\n+    __reportException,\n     runImmediateCallbacks,\n     BadResource,\n     BadResourcePrototype,\n@@ -841,9 +819,6 @@\n     queueSystemTimer: (_associatedOp, repeat, timeout, task) =\u003e\n       op_timer_queue_system(repeat, timeout, task),\n     cancelTimer: (id) =\u003e {\n-      if (timersRunning) {\n-        cancelledTimers.add(id);\n-      }\n       op_timer_cancel(id);\n     },\n     refTimer: (id) =\u003e op_timer_ref(id),\ndiff --git a/core/Cargo.toml b/core/Cargo.toml\nindex d9e3be2..d2dd552 100644\n--- a/core/Cargo.toml\n+++ b/core/Cargo.toml\n@@ -14,7 +14,8 @@ description = \"A modern JavaScript/TypeScript runtime built with V8, Rust, and T\n path = \"lib.rs\"\n \n [features]\n-default = [\"include_icu_data\", \"v8_use_custom_libcxx\"]\n+default = [\"include_icu_data\", \"v8_use_custom_libcxx\", \"reactor-tokio\"]\n+reactor-tokio = []\n include_icu_data = [\"deno_core_icudata\"]\n v8_use_custom_libcxx = [\"v8/use_custom_libcxx\"]\n v8_enable_pointer_compression = [\"v8/v8_enable_pointer_compression\"]\ndiff --git a/core/lib.rs b/core/lib.rs\nindex c1ce078..d45cb19 100644\n--- a/core/lib.rs\n+++ b/core/lib.rs\n@@ -10,6 +10,7 @@ mod async_cancel;\n mod async_cell;\n pub mod convert;\n pub mod cppgc;\n+pub mod event_loop;\n pub mod error;\n mod extension_set;\n mod extensions;\n@@ -26,9 +27,14 @@ mod ops_builtin;\n mod ops_builtin_types;\n mod ops_builtin_v8;\n mod ops_metrics;\n+pub mod reactor;\n+#[cfg(feature = \"reactor-tokio\")]\n+pub mod reactor_tokio;\n mod runtime;\n mod source_map;\n mod tasks;\n+#[allow(non_camel_case_types, non_upper_case_globals, clippy::missing_safety_doc)]\n+pub mod uv_compat;\n mod web_timeout;\n pub mod webidl;\n \ndiff --git a/core/runtime/jsrealm.rs b/core/runtime/jsrealm.rs\nindex fdfca80..ad47ec8 100644\n--- a/core/runtime/jsrealm.rs\n+++ b/core/runtime/jsrealm.rs\n@@ -23,6 +23,9 @@ use crate::modules::script_origin;\n use crate::ops::ExternalOpsTracker;\n use crate::ops::OpCtx;\n use crate::stats::RuntimeActivityTraces;\n+use crate::event_loop::EventLoopPhases;\n+use crate::reactor::DefaultReactor;\n+use crate::uv_compat::UvLoopInner;\n use crate::tasks::V8TaskSpawnerFactory;\n use crate::web_timeout::WebTimers;\n use futures::stream::StreamExt;\n@@ -71,8 +74,17 @@ pub(crate) struct ImmediateInfo {\n \n pub struct ContextState {\n   pub(crate) task_spawner_factory: Arc\u003cV8TaskSpawnerFactory\u003e,\n-  pub(crate) timers: WebTimers\u003c(v8::Global\u003cv8::Function\u003e, u32)\u003e,\n-  pub(crate) js_event_loop_tick_cb: RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n+  pub(crate) timers: WebTimers\u003c(v8::Global\u003cv8::Function\u003e, u32), DefaultReactor\u003e,\n+  // Per-phase JS callbacks (replacing monolithic eventLoopTick)\n+  pub(crate) js_resolve_ops_cb: RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n+  pub(crate) js_drain_next_tick_and_macrotasks_cb:\n+    RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n+  pub(crate) js_handle_rejections_cb:\n+    RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n+  pub(crate) js_set_timer_depth_cb:\n+    RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n+  pub(crate) js_report_exception_cb:\n+    RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n   pub(crate) run_immediate_callbacks_cb:\n     RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n   pub(crate) js_wasm_streaming_cb: RefCell\u003cOption\u003cv8::Global\u003cv8::Function\u003e\u003e\u003e,\n@@ -91,6 +103,11 @@ pub struct ContextState {\n   pub(crate) immediate_info: RefCell\u003cImmediateInfo\u003e,\n   pub(crate) external_ops_tracker: ExternalOpsTracker,\n   pub(crate) ext_import_meta_proto: RefCell\u003cOption\u003cv8::Global\u003cv8::Object\u003e\u003e\u003e,\n+  /// Phase-specific state for the libuv-style event loop.\n+  pub(crate) event_loop_phases: RefCell\u003cEventLoopPhases\u003e,\n+  /// Pointer to the UvLoopInner for the libuv compat layer.\n+  /// Set when a `uv_loop_t` is initialized and associated with this context.\n+  pub(crate) uv_loop_inner: Cell\u003cOption\u003c*const UvLoopInner\u003e\u003e,\n }\n \n impl ContextState {\n@@ -108,7 +125,11 @@ impl ContextState {\n       exception_state: Default::default(),\n       has_next_tick_scheduled: Default::default(),\n       immediate_info: Default::default(),\n-      js_event_loop_tick_cb: Default::default(),\n+      js_resolve_ops_cb: Default::default(),\n+      js_drain_next_tick_and_macrotasks_cb: Default::default(),\n+      js_handle_rejections_cb: Default::default(),\n+      js_set_timer_depth_cb: Default::default(),\n+      js_report_exception_cb: Default::default(),\n       run_immediate_callbacks_cb: Default::default(),\n       js_wasm_streaming_cb: Default::default(),\n       wasm_instance_fn: Default::default(),\n@@ -122,6 +143,8 @@ impl ContextState {\n       unrefed_ops,\n       external_ops_tracker,\n       ext_import_meta_proto: Default::default(),\n+      event_loop_phases: Default::default(),\n+      uv_loop_inner: Cell::new(None),\n     }\n   }\n }\n@@ -209,7 +232,11 @@ impl JsRealmInner {\n     v8::scope!(let scope, \u0026mut isolate);\n     // These globals will prevent snapshots from completing, take them\n     state.exception_state.prepare_to_destroy();\n-    std::mem::take(\u0026mut *state.js_event_loop_tick_cb.borrow_mut());\n+    std::mem::take(\u0026mut *state.js_resolve_ops_cb.borrow_mut());\n+    std::mem::take(\u0026mut *state.js_drain_next_tick_and_macrotasks_cb.borrow_mut());\n+    std::mem::take(\u0026mut *state.js_handle_rejections_cb.borrow_mut());\n+    std::mem::take(\u0026mut *state.js_set_timer_depth_cb.borrow_mut());\n+    std::mem::take(\u0026mut *state.js_report_exception_cb.borrow_mut());\n     std::mem::take(\u0026mut *state.run_immediate_callbacks_cb.borrow_mut());\n     std::mem::take(\u0026mut *state.js_wasm_streaming_cb.borrow_mut());\n \ndiff --git a/core/runtime/jsruntime.rs b/core/runtime/jsruntime.rs\nindex 2b829f9..239e298 100644\n--- a/core/runtime/jsruntime.rs\n+++ b/core/runtime/jsruntime.rs\n@@ -1409,7 +1409,11 @@ impl JsRuntime {\n   /// JsRuntime to operate properly.\n   fn store_js_callbacks(\u0026mut self, realm: \u0026JsRealm, will_snapshot: bool) {\n     let (\n-      event_loop_tick_cb,\n+      resolve_ops_cb,\n+      drain_next_tick_and_macrotasks_cb,\n+      handle_rejections_cb,\n+      set_timer_depth_cb,\n+      report_exception_cb,\n       build_custom_error_cb,\n       run_immediate_callbacks_cb,\n       wasm_instance_fn,\n@@ -1418,18 +1422,41 @@ impl JsRuntime {\n       let context = realm.context();\n       let context_local = v8::Local::new(scope, context);\n       let global = context_local.global(scope);\n-      // TODO(bartlomieju): these probably could be captured from main realm so we don't have to\n-      // look up them again?\n       let deno_obj: v8::Local\u003cv8::Object\u003e =\n         bindings::get(scope, global, DENO, \"Deno\");\n       let core_obj: v8::Local\u003cv8::Object\u003e =\n         bindings::get(scope, deno_obj, CORE, \"Deno.core\");\n \n-      let event_loop_tick_cb: v8::Local\u003cv8::Function\u003e = bindings::get(\n+      let resolve_ops_cb: v8::Local\u003cv8::Function\u003e = bindings::get(\n         scope,\n         core_obj,\n-        EVENT_LOOP_TICK,\n-        \"Deno.core.eventLoopTick\",\n+        RESOLVE_OPS,\n+        \"Deno.core.__resolveOps\",\n+      );\n+      let drain_next_tick_and_macrotasks_cb: v8::Local\u003cv8::Function\u003e =\n+        bindings::get(\n+          scope,\n+          core_obj,\n+          DRAIN_NEXT_TICK_AND_MACROTASKS,\n+          \"Deno.core.__drainNextTickAndMacrotasks\",\n+        );\n+      let handle_rejections_cb: v8::Local\u003cv8::Function\u003e = bindings::get(\n+        scope,\n+        core_obj,\n+        HANDLE_REJECTIONS,\n+        \"Deno.core.__handleRejections\",\n+      );\n+      let set_timer_depth_cb: v8::Local\u003cv8::Function\u003e = bindings::get(\n+        scope,\n+        core_obj,\n+        SET_TIMER_DEPTH,\n+        \"Deno.core.__setTimerDepth\",\n+      );\n+      let report_exception_cb: v8::Local\u003cv8::Function\u003e = bindings::get(\n+        scope,\n+        core_obj,\n+        REPORT_EXCEPTION,\n+        \"Deno.core.__reportException\",\n       );\n       let build_custom_error_cb: v8::Local\u003cv8::Function\u003e = bindings::get(\n         scope,\n@@ -1448,8 +1475,6 @@ impl JsRuntime {\n       if !will_snapshot {\n         let key = WEBASSEMBLY.v8_string(scope).unwrap();\n         if let Some(web_assembly_obj_value) = global.get(scope, key.into()) {\n-          // NOTE(bartlomieju): This is still fallible, because in some V8 modes\n-          // WebAssembly namespace is not available (eg. `--jitless`).\n           let maybe_web_assembly_object =\n             TryInto::\u003cv8::Local\u003cv8::Object\u003e\u003e::try_into(web_assembly_obj_value);\n           if let Ok(web_assembly_object) = maybe_web_assembly_object {\n@@ -1464,7 +1489,11 @@ impl JsRuntime {\n       }\n \n       (\n-        v8::Global::new(scope, event_loop_tick_cb),\n+        v8::Global::new(scope, resolve_ops_cb),\n+        v8::Global::new(scope, drain_next_tick_and_macrotasks_cb),\n+        v8::Global::new(scope, handle_rejections_cb),\n+        v8::Global::new(scope, set_timer_depth_cb),\n+        v8::Global::new(scope, report_exception_cb),\n         v8::Global::new(scope, build_custom_error_cb),\n         v8::Global::new(scope, run_immediate_callbacks_cb),\n         wasm_instance_fn.map(|f| v8::Global::new(scope, f)),\n@@ -1474,9 +1503,25 @@ impl JsRuntime {\n     // Put global handles in the realm's ContextState\n     let state_rc = realm.0.state();\n     state_rc\n-      .js_event_loop_tick_cb\n+      .js_resolve_ops_cb\n       .borrow_mut()\n-      .replace(event_loop_tick_cb);\n+      .replace(resolve_ops_cb);\n+    state_rc\n+      .js_drain_next_tick_and_macrotasks_cb\n+      .borrow_mut()\n+      .replace(drain_next_tick_and_macrotasks_cb);\n+    state_rc\n+      .js_handle_rejections_cb\n+      .borrow_mut()\n+      .replace(handle_rejections_cb);\n+    state_rc\n+      .js_set_timer_depth_cb\n+      .borrow_mut()\n+      .replace(set_timer_depth_cb);\n+    state_rc\n+      .js_report_exception_cb\n+      .borrow_mut()\n+      .replace(report_exception_cb);\n     state_rc\n       .exception_state\n       .js_build_custom_error_cb\n@@ -1915,6 +1960,16 @@ impl JsRuntime {\n     self.poll_event_loop_inner(cx, \u0026mut scope, poll_options)\n   }\n \n+  /// Phase-based event loop tick, matching libuv's architecture:\n+  ///\n+  /// Phase 1: Timers - poll expired timer callbacks\n+  /// Phase 2: Pending callbacks - completed async ops, promise rejections\n+  /// Phase 3: Idle/Prepare - task spawner, module progress\n+  /// Phase 4: Poll - drive async reactor I/O\n+  /// Phase 5: Check - setImmediate callbacks\n+  /// Phase 6: Close callbacks - resource cleanup\n+  ///\n+  /// Microtask checkpoints run between each phase.\n   fn poll_event_loop_inner(\n     \u0026self,\n     cx: \u0026mut Context,\n@@ -1924,11 +1979,10 @@ impl JsRuntime {\n     let has_inspector = self.inner.state.has_inspector.get();\n     self.inner.state.waker.register(cx.waker());\n \n+    // Pre-phase: Inspector + V8 message loop pump\n     if has_inspector {\n-      // We poll the inspector first.\n       self.inspector().poll_sessions_from_event_loop(cx);\n     }\n-\n     if poll_options.pump_v8_message_loop {\n       self.pump_v8_message_loop(scope)?;\n     }\n@@ -1938,21 +1992,84 @@ impl JsRuntime {\n     let context_state = \u0026realm.0.context_state;\n     let exception_state = \u0026context_state.exception_state;\n \n+    let mut dispatched_ops = false;\n+    let mut did_work = false;\n+\n+    // ===== Phase 1 (Timers) =====\n+    // 1a. Fire expired libuv C timers\n+    if let Some(uv_inner_ptr) = context_state.uv_loop_inner.get() {\n+      unsafe { (*uv_inner_ptr).run_timers() };\n+    }\n+    // 1b. Fire expired JS timers (direct v8::Function::call per timer)\n+    did_work |= Self::dispatch_timers(cx, scope, context_state)?;\n+    scope.perform_microtask_checkpoint();\n+\n+    // ===== Phase 2 (Pending callbacks) =====\n+    // Module progress polling (before ops, matching original ordering)\n     modules.poll_progress(cx, scope)?;\n \n-    // Resolve async ops, run all next tick callbacks and macrotasks callbacks\n-    // and only then check for any promise exceptions (`unhandledrejection`\n-    // handlers are run in macrotasks callbacks so we need to let them run\n-    // first).\n-    let (dispatched_ops, did_work) = Self::do_js_event_loop_tick_realm(\n-      cx,\n-      scope,\n-      context_state,\n-      exception_state,\n-    )?;\n+    // 2a. V8 task spawner tasks\n+    dispatched_ops |=\n+      Self::dispatch_task_spawner(cx, scope, context_state);\n+\n+    // 2b. Poll and resolve completed async ops\n+    // NOTE: No microtask checkpoint between ops and nextTick/macrotask!\n+    // This matches the old eventLoopTick behavior where ops resolve,\n+    // nextTick drains, and macrotasks run all within the same JS call\n+    // before any microtask checkpoint. Promise continuations (like await\n+    // resumption) run only after all three have completed.\n+    dispatched_ops |=\n+      Self::dispatch_pending_ops(cx, scope, context_state)?;\n+\n+    // 2c. nextTick drain + macrotask drain (before microtask checkpoint)\n+    // Only drain if there's actual work (ops dispatched, tick scheduled, or timers fired).\n+    // This prevents macrotask callbacks from running on empty iterations.\n+    let has_tick_scheduled = context_state.has_next_tick_scheduled.get();\n+    dispatched_ops |= has_tick_scheduled;\n+    if dispatched_ops || did_work || has_tick_scheduled {\n+      Self::drain_next_tick_and_macrotasks(scope, context_state)?;\n+    }\n+\n+    // 2d. Immediates (if ops or timers did work)\n+    if (did_work || dispatched_ops)\n+      \u0026\u0026 context_state.immediate_info.borrow().ref_count \u003e 0\n+    {\n+      Self::do_js_run_immediate_callbacks(scope, context_state)?;\n+    }\n+\n+    // 2e. Handle promise rejections (after nextTick/macrotask, since\n+    // unhandledrejection handlers are run in macrotask callbacks)\n+    Self::dispatch_rejections(scope, context_state, exception_state)?;\n+    scope.perform_microtask_checkpoint();\n+\n+    // ===== Phase 3 (Idle/Prepare) =====\n+    if let Some(uv_inner_ptr) = context_state.uv_loop_inner.get() {\n+      unsafe {\n+        (*uv_inner_ptr).run_idle();\n+        (*uv_inner_ptr).run_prepare();\n+      };\n+    }\n+    scope.perform_microtask_checkpoint();\n+\n+    // ===== Phase 5 (Check) =====\n+    // libuv check callbacks\n+    if let Some(uv_inner_ptr) = context_state.uv_loop_inner.get() {\n+      unsafe { (*uv_inner_ptr).run_check() };\n+    }\n+    scope.perform_microtask_checkpoint();\n+\n+    // ===== Phase 6 (Close) =====\n     exception_state.check_exception_condition(scope)?;\n+    {\n+      let mut phases = context_state.event_loop_phases.borrow_mut();\n+      phases.run_close_callbacks();\n+    }\n+    if let Some(uv_inner_ptr) = context_state.uv_loop_inner.get() {\n+      unsafe { (*uv_inner_ptr).run_close() };\n+    }\n+    scope.perform_microtask_checkpoint();\n \n-    // Get the pending state from the main realm, or all realms\n+    // Evaluate pending state\n     let pending_state =\n       EventLoopPendingState::new(scope, context_state, modules);\n \n@@ -1978,25 +2095,13 @@ impl JsRuntime {\n       return Poll::Ready(Ok(()));\n     }\n \n-    // eprintln!(\n-    //   \"did work {}, dispatched_ops {}, has timers {}, has_refed_immediates {}, has_outstanding_immediates {}\",\n-    //   did_work,\n-    //   dispatched_ops,\n-    //   context_state.timers.has_pending(),\n-    //   pending_state.has_refed_immediates,\n-    //   pending_state.has_outstanding_immediates\n-    // );\n-    if !did_work \u0026\u0026 pending_state.has_refed_immediates \u003e 0 {\n+    // Run immediates if not already run above and there are refed immediates pending\n+    if !did_work \u0026\u0026 !dispatched_ops \u0026\u0026 pending_state.has_refed_immediates \u003e 0 {\n       Self::do_js_run_immediate_callbacks(scope, context_state)?;\n+      scope.perform_microtask_checkpoint();\n     }\n \n-    // Check if more async ops have been dispatched\n-    // during this turn of event loop.\n-    // If there are any pending background tasks, we also wake the runtime to\n-    // make sure we don't miss them.\n-    // TODO(andreubotella) The event loop will spin as long as there are pending\n-    // background tasks. We should look into having V8 notify us when a\n-    // background task is done.\n+    // Re-wake logic for next iteration\n     #[allow(clippy::suspicious_else_formatting, clippy::if_same_then_else)]\n     {\n       if pending_state.has_pending_background_tasks\n@@ -2053,9 +2158,6 @@ impl JsRuntime {\n           .into_box(),\n         ));\n       } else {\n-        // Delay the above error by one spin of the event loop. A dynamic import\n-        // evaluation may complete during this, in which case the counter will\n-        // reset.\n         realm.increment_modules_idle();\n         self.inner.state.waker.wake();\n       }\n@@ -2561,55 +2663,133 @@ impl JsRuntime {\n     Ok(())\n   }\n \n-  fn do_js_event_loop_tick_realm\u003c's, 'i\u003e(\n+  /// Phase 1 (Timers): Poll JS WebTimers, dispatch each callback directly\n+  /// via v8::Function::call. Microtask checkpoint + nextTick drain between\n+  /// each timer callback.\n+  fn dispatch_timers\u003c's, 'i\u003e(\n     cx: \u0026mut Context,\n     scope: \u0026mut v8::PinScope\u003c's, 'i\u003e,\n     context_state: \u0026ContextState,\n-    exception_state: \u0026ExceptionState,\n-  ) -\u003e Result\u003c(bool, bool), Box\u003cJsError\u003e\u003e {\n-    let mut dispatched_ops = false;\n-    let mut did_work = false;\n+  ) -\u003e Result\u003cbool, Box\u003cJsError\u003e\u003e {\n+    let timers = match context_state.timers.poll_timers(cx) {\n+      Poll::Ready(timers) =\u003e timers,\n+      _ =\u003e return Ok(false),\n+    };\n+\n+    if timers.is_empty() {\n+      return Ok(false);\n+    }\n+\n+    let traces_enabled = context_state.activity_traces.is_enabled();\n+    let undefined: v8::Local\u003cv8::Value\u003e = v8::undefined(scope).into();\n+\n+    for (timer_id, (callback, depth)) in \u0026timers {\n+      if traces_enabled {\n+        context_state\n+          .activity_traces\n+          .complete(RuntimeActivityType::Timer, *timer_id as _);\n+      }\n+\n+      // Set timer depth via JS setter\n+      {\n+        let set_timer_depth_cb =\n+          context_state.js_set_timer_depth_cb.borrow();\n+        let set_timer_depth_fn =\n+          set_timer_depth_cb.as_ref().unwrap().open(scope);\n+        let depth_val = v8::Integer::new(scope, *depth as i32);\n+        set_timer_depth_fn.call(scope, undefined, \u0026[depth_val.into()]);\n+      }\n+\n+      // Call the timer callback directly\n+      {\n+        v8::tc_scope!(let tc_scope, scope);\n+        let cb = callback.open(tc_scope);\n+        cb.call(tc_scope, undefined, \u0026[]);\n+\n+        if let Some(exception) = tc_scope.exception() {\n+          // Report exception but don't abort the timer loop.\n+          // Globalize the exception value, then get report fn and call it.\n+          let exc_global = v8::Global::new(tc_scope, exception);\n+          {\n+            let report_exception_cb =\n+              context_state.js_report_exception_cb.borrow();\n+            if let Some(report_fn_global) = report_exception_cb.as_ref() {\n+              let report_fn = report_fn_global.open(tc_scope);\n+              let exc_local = v8::Local::new(tc_scope, \u0026exc_global);\n+              report_fn.call(tc_scope, undefined, \u0026[exc_local]);\n+            }\n+          }\n+        }\n+      }\n+\n+      // Microtask checkpoint between each timer\n+      scope.perform_microtask_checkpoint();\n+\n+      // Drain nextTick between each timer callback\n+      {\n+        let has_tick = context_state.has_next_tick_scheduled.get();\n+        let drain_cb =\n+          context_state.js_drain_next_tick_and_macrotasks_cb.borrow();\n+        let drain_fn = drain_cb.as_ref().unwrap().open(scope);\n+        let has_tick_val = v8::Boolean::new(scope, has_tick);\n+        drain_fn.call(scope, undefined, \u0026[has_tick_val.into()]);\n+      }\n+\n+      scope.perform_microtask_checkpoint();\n+    }\n+\n+    // Reset timer depth to 0 after all timers\n+    {\n+      let set_timer_depth_cb =\n+        context_state.js_set_timer_depth_cb.borrow();\n+      let set_timer_depth_fn =\n+        set_timer_depth_cb.as_ref().unwrap().open(scope);\n+      let zero = v8::Integer::new(scope, 0);\n+      set_timer_depth_fn.call(scope, undefined, \u0026[zero.into()]);\n+    }\n+\n+    Ok(true)\n+  }\n \n-    // Poll any pending task spawner tasks. Note that we need to poll separately because otherwise\n-    // Rust will extend the lifetime of the borrow longer than we expect.\n+  /// Phase 2a: Poll and dispatch V8 task spawner tasks.\n+  fn dispatch_task_spawner(\n+    cx: \u0026mut Context,\n+    scope: \u0026mut v8::PinScope,\n+    context_state: \u0026ContextState,\n+  ) -\u003e bool {\n+    let mut dispatched = false;\n     let mut retries = 3;\n     while let Poll::Ready(tasks) =\n       context_state.task_spawner_factory.poll_inner(cx)\n     {\n-      // TODO(mmastrac): we are using this flag\n-      dispatched_ops = true;\n+      dispatched = true;\n       for task in tasks {\n         task(scope);\n       }\n-      // We may need to perform a microtask checkpoint here\n       scope.perform_microtask_checkpoint();\n \n-      // We don't want tasks that spawn other tasks to starve the event loop, so break\n-      // after three times around and allow the remainder of the event loop to spin.\n       retries -= 1;\n       if retries == 0 {\n         cx.waker().wake_by_ref();\n         break;\n       }\n     }\n+    dispatched\n+  }\n \n-    // We return async responses to JS in bounded batches. Note that because\n-    // we're passing these to JS as arguments, it is possible to overflow the\n-    // JS stack by just passing too many.\n+  /// Phase 2b: Poll completed async ops and batch-resolve via JS __resolveOps.\n+  fn dispatch_pending_ops\u003c's, 'i\u003e(\n+    cx: \u0026mut Context,\n+    scope: \u0026mut v8::PinScope\u003c's, 'i\u003e,\n+    context_state: \u0026ContextState,\n+  ) -\u003e Result\u003cbool, Box\u003cJsError\u003e\u003e {\n     const MAX_VEC_SIZE_FOR_OPS: usize = 1024;\n \n-    // each batch is a flat vector of tuples:\n-    // `[promise_id1, op_result1, promise_id2, op_result2, ...]`\n-    // promise_id is a simple integer, op_result is an ops::OpResult\n-    // which contains a value OR an error, encoded as a tuple.\n-    // This batch is received in JS via the special `arguments` variable\n-    // and then each tuple is used to resolve or reject promises\n     let mut args: SmallVec\u003c[v8::Local\u003cv8::Value\u003e; 32]\u003e =\n       SmallVec::with_capacity(32);\n \n     loop {\n       if args.len() \u003e= MAX_VEC_SIZE_FOR_OPS {\n-        // We have too many, bail for now but re-wake the waker\n         cx.waker().wake_by_ref();\n         break;\n       }\n@@ -2637,17 +2817,42 @@ impl JsRuntime {\n       context_state\n         .activity_traces\n         .complete(RuntimeActivityType::AsyncOp, promise_id as _);\n-      dispatched_ops |= true;\n-      did_work |= true;\n       args.push(v8::Integer::new(scope, promise_id).into());\n       args.push(v8::Boolean::new(scope, res.is_ok()).into());\n       args.push(res.unwrap_or_else(std::convert::identity));\n     }\n \n+    if args.is_empty() {\n+      return Ok(false);\n+    }\n+\n+    let undefined: v8::Local\u003cv8::Value\u003e = v8::undefined(scope).into();\n+\n+    v8::tc_scope!(let tc_scope, scope);\n+\n+    let resolve_ops_cb = context_state.js_resolve_ops_cb.borrow();\n+    let resolve_ops_fn = resolve_ops_cb.as_ref().unwrap().open(tc_scope);\n+    resolve_ops_fn.call(tc_scope, undefined, args.as_slice());\n+\n+    if let Some(exception) = tc_scope.exception() {\n+      return exception_to_err_result(tc_scope, exception, false, true);\n+    }\n+    if tc_scope.has_terminated() || tc_scope.is_execution_terminating() {\n+      return Ok(false);\n+    }\n+\n+    Ok(true)\n+  }\n+\n+  /// Phase 2c: Handle promise rejections.\n+  fn dispatch_rejections\u003c's, 'i\u003e(\n+    scope: \u0026mut v8::PinScope\u003c's, 'i\u003e,\n+    context_state: \u0026ContextState,\n+    exception_state: \u0026ExceptionState,\n+  ) -\u003e Result\u003c(), Box\u003cJsError\u003e\u003e {\n     let undefined: v8::Local\u003cv8::Value\u003e = v8::undefined(scope).into();\n-    let has_tick_scheduled = context_state.has_next_tick_scheduled.get();\n-    dispatched_ops |= has_tick_scheduled;\n \n+    // First handle \"handled\" rejections\n     while let Some((promise, result)) = exception_state\n       .pending_handled_promise_rejections\n       .borrow_mut()\n@@ -2659,7 +2864,6 @@ impl JsRuntime {\n         .as_ref()\n       {\n         let function = handler.open(scope);\n-\n         let args = [\n           v8::Local::new(scope, promise).into(),\n           v8::Local::new(scope, result),\n@@ -2668,84 +2872,64 @@ impl JsRuntime {\n       }\n     }\n \n-    let rejections = if !exception_state\n+    // Then handle unhandled rejections\n+    if exception_state\n       .pending_promise_rejections\n-      .borrow_mut()\n+      .borrow()\n       .is_empty()\n     {\n-      // Avoid holding the pending rejection lock longer than necessary\n-      let mut pending_rejections =\n-        exception_state.pending_promise_rejections.borrow_mut();\n-      let mut rejections = VecDeque::default();\n-      std::mem::swap(\u0026mut *pending_rejections, \u0026mut rejections);\n-      drop(pending_rejections);\n-\n-      let arr = v8::Array::new(scope, (rejections.len() * 2) as i32);\n-      let mut index = 0;\n-      for rejection in rejections.into_iter() {\n-        let value = v8::Local::new(scope, rejection.0);\n-        arr.set_index(scope, index, value.into());\n-        index += 1;\n-        let value = v8::Local::new(scope, rejection.1);\n-        arr.set_index(scope, index, value);\n-        index += 1;\n-      }\n-      arr.into()\n-    } else {\n-      undefined\n-    };\n-\n-    args.push(rejections);\n-\n-    // TODO(mmastrac): timer dispatch should be done via direct function call, but we will have to start\n-    // storing the exception-reporting callback.\n-    let timers = match context_state.timers.poll_timers(cx) {\n-      Poll::Ready(timers) =\u003e {\n-        did_work |= true;\n-        let traces_enabled = context_state.activity_traces.is_enabled();\n-        let arr = v8::Array::new(scope, (timers.len() * 3) as _);\n-        #[allow(clippy::needless_range_loop)]\n-        for i in 0..timers.len() {\n-          if traces_enabled {\n-            // Timer and interval traces both use RuntimeActivityType::Timer\n-            context_state\n-              .activity_traces\n-              .complete(RuntimeActivityType::Timer, timers[i].0 as _);\n-          }\n-          // depth, id, function\n-          let value = v8::Integer::new(scope, timers[i].1.1 as _);\n-          arr.set_index(scope, (i * 3) as _, value.into());\n-          let value = v8::Number::new(scope, timers[i].0 as _);\n-          arr.set_index(scope, (i * 3 + 1) as _, value.into());\n-          let value = v8::Local::new(scope, timers[i].1.0.clone());\n-          arr.set_index(scope, (i * 3 + 2) as _, value.into());\n-        }\n-        arr.into()\n-      }\n-      _ =\u003e undefined,\n-    };\n-    args.push(timers);\n+      return Ok(());\n+    }\n \n-    let has_tick_scheduled = v8::Boolean::new(scope, has_tick_scheduled);\n-    args.push(has_tick_scheduled.into());\n+    let mut pending_rejections =\n+      exception_state.pending_promise_rejections.borrow_mut();\n+    let mut rejections = VecDeque::default();\n+    std::mem::swap(\u0026mut *pending_rejections, \u0026mut rejections);\n+    drop(pending_rejections);\n+\n+    let mut args: SmallVec\u003c[v8::Local\u003cv8::Value\u003e; 16]\u003e =\n+      SmallVec::with_capacity(rejections.len() * 2);\n+    for rejection in rejections.into_iter() {\n+      args.push(v8::Local::new(scope, rejection.0).into());\n+      args.push(v8::Local::new(scope, rejection.1));\n+    }\n \n     v8::tc_scope!(let tc_scope, scope);\n \n-    let js_event_loop_tick_cb = context_state.js_event_loop_tick_cb.borrow();\n-    let js_event_loop_tick_cb =\n-      js_event_loop_tick_cb.as_ref().unwrap().open(tc_scope);\n-\n-    js_event_loop_tick_cb.call(tc_scope, undefined, args.as_slice());\n+    let handle_rejections_cb =\n+      context_state.js_handle_rejections_cb.borrow();\n+    let handle_rejections_fn =\n+      handle_rejections_cb.as_ref().unwrap().open(tc_scope);\n+    handle_rejections_fn.call(tc_scope, undefined, args.as_slice());\n \n     if let Some(exception) = tc_scope.exception() {\n       return exception_to_err_result(tc_scope, exception, false, true);\n     }\n \n-    if tc_scope.has_terminated() || tc_scope.is_execution_terminating() {\n-      return Ok((false, false));\n+    Ok(())\n+  }\n+\n+  /// Phase 5a: Drain nextTick queue and macrotask queue.\n+  fn drain_next_tick_and_macrotasks\u003c's, 'i\u003e(\n+    scope: \u0026mut v8::PinScope\u003c's, 'i\u003e,\n+    context_state: \u0026ContextState,\n+  ) -\u003e Result\u003c(), Box\u003cJsError\u003e\u003e {\n+    let undefined: v8::Local\u003cv8::Value\u003e = v8::undefined(scope).into();\n+    let has_tick_scheduled = context_state.has_next_tick_scheduled.get();\n+\n+    v8::tc_scope!(let tc_scope, scope);\n+\n+    let drain_cb =\n+      context_state.js_drain_next_tick_and_macrotasks_cb.borrow();\n+    let drain_fn = drain_cb.as_ref().unwrap().open(tc_scope);\n+    let has_tick_val = v8::Boolean::new(tc_scope, has_tick_scheduled);\n+    drain_fn.call(tc_scope, undefined, \u0026[has_tick_val.into()]);\n+\n+    if let Some(exception) = tc_scope.exception() {\n+      return exception_to_err_result(tc_scope, exception, false, true);\n     }\n \n-    Ok((dispatched_ops, did_work))\n+    Ok(())\n   }\n }\n \ndiff --git a/core/runtime/v8_static_strings.rs b/core/runtime/v8_static_strings.rs\nindex 78e9216..269f7fa 100644\n--- a/core/runtime/v8_static_strings.rs\n+++ b/core/runtime/v8_static_strings.rs\n@@ -25,7 +25,11 @@ v8_static_strings!(\n   DIRNAME = \"dirname\",\n   ERR_MODULE_NOT_FOUND = \"ERR_MODULE_NOT_FOUND\",\n   ERRORS = \"errors\",\n-  EVENT_LOOP_TICK = \"eventLoopTick\",\n+  RESOLVE_OPS = \"__resolveOps\",\n+  DRAIN_NEXT_TICK_AND_MACROTASKS = \"__drainNextTickAndMacrotasks\",\n+  HANDLE_REJECTIONS = \"__handleRejections\",\n+  SET_TIMER_DEPTH = \"__setTimerDepth\",\n+  REPORT_EXCEPTION = \"__reportException\",\n   RUN_IMMEDIATE_CALLBACKS = \"runImmediateCallbacks\",\n   FILENAME = \"filename\",\n   INSTANCE = \"Instance\",\ndiff --git a/core/web_timeout.rs b/core/web_timeout.rs\nindex 3d7faf8..319ca12 100644\n--- a/core/web_timeout.rs\n+++ b/core/web_timeout.rs\n@@ -1,5 +1,8 @@\n // Copyright 2018-2025 the Deno authors. MIT license.\n \n+use crate::reactor::Reactor;\n+use crate::reactor::ReactorInstant;\n+use crate::reactor::ReactorTimer;\n use cooked_waker::IntoWaker;\n use cooked_waker::ViaRawPointer;\n use cooked_waker::Wake;\n@@ -11,7 +14,6 @@ use std::cell::UnsafeCell;\n use std::collections::BTreeMap;\n use std::collections::BTreeSet;\n use std::collections::btree_set;\n-use std::future::Future;\n use std::mem::MaybeUninit;\n use std::num::NonZeroU64;\n use std::pin::Pin;\n@@ -20,8 +22,6 @@ use std::task::Poll;\n use std::task::Waker;\n use std::task::ready;\n use std::time::Duration;\n-use tokio::time::Instant;\n-use tokio::time::Sleep;\n \n pub(crate) type WebTimerId = u64;\n \n@@ -35,7 +35,7 @@ enum TimerType {\n }\n \n #[derive(PartialEq, Eq, PartialOrd, Ord)]\n-struct TimerKey(Instant, u64, TimerType, bool);\n+struct TimerKey\u003cI: ReactorInstant\u003e(I, u64, TimerType, bool);\n \n struct TimerData\u003cT\u003e {\n   data: T,\n@@ -76,23 +76,31 @@ struct TimerData\u003cT\u003e {\n /// https://github.com/denoland/deno/pull/12862 -- Refactor timers to use one async op per timer\n ///\n /// https://github.com/denoland/deno/issues/11398 -- Spurious assertion error when the callback to setInterval lasts longer than the interval\n-pub(crate) struct WebTimers\u003cT\u003e {\n+pub(crate) struct WebTimers\u003cT, R: Reactor\u003e {\n+  reactor: R,\n   next_id: Cell\u003cWebTimerId\u003e,\n-  timers: RefCell\u003cBTreeSet\u003cTimerKey\u003e\u003e,\n+  timers: RefCell\u003cBTreeSet\u003cTimerKey\u003cR::Instant\u003e\u003e\u003e,\n   /// We choose a `BTreeMap` over `HashMap` because of memory performance.\n   data_map: RefCell\u003cBTreeMap\u003cWebTimerId, TimerData\u003cT\u003e\u003e\u003e,\n   /// How many unref'd timers exist?\n   unrefd_count: Cell\u003cusize\u003e,\n-  /// A boxed MutableSleep that will allow us to change the Tokio sleep timeout as needed.\n+  /// A boxed MutableSleep that will allow us to change the timer timeout as needed.\n   /// Because this is boxed, we can \"safely\" unsafely poll it.\n-  sleep: Box\u003cMutableSleep\u003e,\n+  sleep: Box\u003cMutableSleep\u003cR::Timer\u003e\u003e,\n   /// The high-res timer lock. No-op on platforms other than Windows.\n   high_res_timer_lock: HighResTimerLock,\n }\n \n-impl\u003cT\u003e Default for WebTimers\u003cT\u003e {\n+impl\u003cT, R: Reactor + Default\u003e Default for WebTimers\u003cT, R\u003e {\n   fn default() -\u003e Self {\n+    Self::new(R::default())\n+  }\n+}\n+\n+impl\u003cT, R: Reactor\u003e WebTimers\u003cT, R\u003e {\n+  pub fn new(reactor: R) -\u003e Self {\n     Self {\n+      reactor,\n       next_id: Default::default(),\n       timers: Default::default(),\n       data_map: Default::default(),\n@@ -101,22 +109,22 @@ impl\u003cT\u003e Default for WebTimers\u003cT\u003e {\n       high_res_timer_lock: Default::default(),\n     }\n   }\n-}\n \n-impl\u003cT\u003e WebTimers\u003cT\u003e {\n   #[allow(unused)]\n   pub fn has_pending(\u0026self) -\u003e bool {\n     !self.timers.borrow().is_empty()\n   }\n }\n \n-pub(crate) struct WebTimersIterator\u003c'a, T\u003e {\n+pub(crate) struct WebTimersIterator\u003c'a, T, I: ReactorInstant\u003e {\n   data: Ref\u003c'a, BTreeMap\u003cWebTimerId, TimerData\u003cT\u003e\u003e\u003e,\n-  timers: Ref\u003c'a, BTreeSet\u003cTimerKey\u003e\u003e,\n+  timers: Ref\u003c'a, BTreeSet\u003cTimerKey\u003cI\u003e\u003e\u003e,\n }\n \n-impl\u003c'a, T\u003e IntoIterator for \u0026'a WebTimersIterator\u003c'a, T\u003e {\n-  type IntoIter = WebTimersIteratorImpl\u003c'a, T\u003e;\n+impl\u003c'a, T, I: ReactorInstant\u003e IntoIterator\n+  for \u0026'a WebTimersIterator\u003c'a, T, I\u003e\n+{\n+  type IntoIter = WebTimersIteratorImpl\u003c'a, T, I\u003e;\n   type Item = (u64, bool, bool);\n \n   fn into_iter(self) -\u003e Self::IntoIter {\n@@ -127,12 +135,12 @@ impl\u003c'a, T\u003e IntoIterator for \u0026'a WebTimersIterator\u003c'a, T\u003e {\n   }\n }\n \n-pub(crate) struct WebTimersIteratorImpl\u003c'a, T\u003e {\n+pub(crate) struct WebTimersIteratorImpl\u003c'a, T, I: ReactorInstant\u003e {\n   data: \u0026'a BTreeMap\u003cWebTimerId, TimerData\u003cT\u003e\u003e,\n-  timers: btree_set::Iter\u003c'a, TimerKey\u003e,\n+  timers: btree_set::Iter\u003c'a, TimerKey\u003cI\u003e\u003e,\n }\n \n-impl\u003cT\u003e Iterator for WebTimersIteratorImpl\u003c'_, T\u003e {\n+impl\u003cT, I: ReactorInstant\u003e Iterator for WebTimersIteratorImpl\u003c'_, T, I\u003e {\n   type Item = (u64, bool, bool);\n   fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n     loop {\n@@ -144,15 +152,15 @@ impl\u003cT\u003e Iterator for WebTimersIteratorImpl\u003c'_, T\u003e {\n   }\n }\n \n-struct MutableSleep {\n-  sleep: UnsafeCell\u003cOption\u003cSleep\u003e\u003e,\n+struct MutableSleep\u003cTmr: ReactorTimer\u003e {\n+  sleep: UnsafeCell\u003cOption\u003cTmr\u003e\u003e,\n   ready: Cell\u003cbool\u003e,\n   external_waker: UnsafeCell\u003cOption\u003cWaker\u003e\u003e,\n   internal_waker: Waker,\n }\n \n #[allow(clippy::borrowed_box)]\n-impl MutableSleep {\n+impl\u003cTmr: ReactorTimer + 'static\u003e MutableSleep\u003cTmr\u003e {\n   fn new() -\u003e Box\u003cSelf\u003e {\n     let mut new = Box::new(MaybeUninit::\u003cSelf\u003e::uninit());\n \n@@ -160,7 +168,7 @@ impl MutableSleep {\n       sleep: Default::default(),\n       ready: Cell::default(),\n       external_waker: UnsafeCell::default(),\n-      internal_waker: MutableSleepWaker {\n+      internal_waker: MutableSleepWaker::\u003cTmr\u003e {\n         inner: new.as_ptr(),\n       }\n       .into_waker(),\n@@ -181,14 +189,15 @@ impl MutableSleep {\n           external.clone_from(waker);\n         }\n \n-        // We do a manual deadline check here. Tokio's timer wheel may not immediately check the deadline if the\n+        // We do a manual deadline check here. The timer wheel may not immediately check the deadline if the\n         // executor was blocked.\n         // Skip this check under Miri as it interferes with time simulation.\n         #[cfg(not(miri))]\n         {\n-          let sleep = unsafe { self.sleep.get().as_mut().unwrap_unchecked() };\n+          let sleep =\n+            unsafe { self.sleep.get().as_mut().unwrap_unchecked() };\n           if let Some(sleep) = sleep\n-            \u0026\u0026 Instant::now() \u003e= sleep.deadline()\n+            \u0026\u0026 Tmr::Instant::now() \u003e= sleep.deadline()\n           {\n             return Poll::Ready(());\n           }\n@@ -208,10 +217,10 @@ impl MutableSleep {\n     self.ready.set(false);\n   }\n \n-  fn change(self: \u0026Box\u003cSelf\u003e, instant: Instant) {\n+  fn change(self: \u0026Box\u003cSelf\u003e, timer: Tmr) {\n     let pin = unsafe {\n-      // First replace the current sleep\n-      *self.sleep.get() = Some(tokio::time::sleep_until(instant));\n+      // First replace the current timer\n+      *self.sleep.get() = Some(timer);\n \n       // Then get ourselves a Pin to this\n       Pin::new_unchecked(\n@@ -235,15 +244,20 @@ impl MutableSleep {\n }\n \n #[repr(transparent)]\n-#[derive(Clone)]\n-struct MutableSleepWaker {\n-  inner: *const MutableSleep,\n+struct MutableSleepWaker\u003cTmr: ReactorTimer\u003e {\n+  inner: *const MutableSleep\u003cTmr\u003e,\n }\n \n-unsafe impl Send for MutableSleepWaker {}\n-unsafe impl Sync for MutableSleepWaker {}\n+impl\u003cTmr: ReactorTimer\u003e Clone for MutableSleepWaker\u003cTmr\u003e {\n+  fn clone(\u0026self) -\u003e Self {\n+    MutableSleepWaker { inner: self.inner }\n+  }\n+}\n \n-impl WakeRef for MutableSleepWaker {\n+unsafe impl\u003cTmr: ReactorTimer\u003e Send for MutableSleepWaker\u003cTmr\u003e {}\n+unsafe impl\u003cTmr: ReactorTimer\u003e Sync for MutableSleepWaker\u003cTmr\u003e {}\n+\n+impl\u003cTmr: ReactorTimer\u003e WakeRef for MutableSleepWaker\u003cTmr\u003e {\n   fn wake_by_ref(\u0026self) {\n     unsafe {\n       let this = self.inner.as_ref().unwrap_unchecked();\n@@ -256,17 +270,17 @@ impl WakeRef for MutableSleepWaker {\n   }\n }\n \n-impl Wake for MutableSleepWaker {\n+impl\u003cTmr: ReactorTimer\u003e Wake for MutableSleepWaker\u003cTmr\u003e {\n   fn wake(self) {\n     self.wake_by_ref()\n   }\n }\n \n-impl Drop for MutableSleepWaker {\n+impl\u003cTmr: ReactorTimer\u003e Drop for MutableSleepWaker\u003cTmr\u003e {\n   fn drop(\u0026mut self) {}\n }\n \n-unsafe impl ViaRawPointer for MutableSleepWaker {\n+unsafe impl\u003cTmr: ReactorTimer\u003e ViaRawPointer for MutableSleepWaker\u003cTmr\u003e {\n   type Target = ();\n \n   fn into_raw(self) -\u003e *mut () {\n@@ -278,10 +292,10 @@ unsafe impl ViaRawPointer for MutableSleepWaker {\n   }\n }\n \n-impl\u003cT: Clone\u003e WebTimers\u003cT\u003e {\n+impl\u003cT: Clone, R: Reactor\u003e WebTimers\u003cT, R\u003e {\n   /// Returns an internal iterator that locks the internal data structures for the period\n   /// of iteration. Calling other methods on this collection will cause a panic.\n-  pub(crate) fn iter(\u0026self) -\u003e WebTimersIterator\u003c'_, T\u003e {\n+  pub(crate) fn iter(\u0026self) -\u003e WebTimersIterator\u003c'_, T, R::Instant\u003e {\n     WebTimersIterator {\n       data: self.data_map.borrow(),\n       timers: self.timers.borrow(),\n@@ -341,17 +355,19 @@ impl\u003cT: Clone\u003e WebTimers\u003cT\u003e {\n     self.next_id.set(id);\n \n     let mut timers = self.timers.borrow_mut();\n-    let deadline = Instant::now()\n+    let deadline = self\n+      .reactor\n+      .now()\n       .checked_add(Duration::from_millis(timeout_ms))\n       .unwrap();\n     match timers.first() {\n       Some(TimerKey(k, ..)) =\u003e {\n         if \u0026deadline \u003c k {\n-          self.sleep.change(deadline);\n+          self.sleep.change(self.reactor.timer(deadline));\n         }\n       }\n       _ =\u003e {\n-        self.sleep.change(deadline);\n+        self.sleep.change(self.reactor.timer(deadline));\n       }\n     }\n \n@@ -411,12 +427,13 @@ impl\u003cT: Clone\u003e WebTimers\u003cT\u003e {\n   /// Poll for any timers that have completed.\n   pub fn poll_timers(\u0026self, cx: \u0026mut Context) -\u003e Poll\u003cVec\u003c(u64, T)\u003e\u003e {\n     ready!(self.sleep.poll_ready(cx));\n-    let now = Instant::now();\n+    let now = R::Instant::now();\n     let mut timers = self.timers.borrow_mut();\n     let mut data = self.data_map.borrow_mut();\n     let mut output = vec![];\n \n-    let mut split = timers.split_off(\u0026TimerKey(now, 0, TimerType::Once, false));\n+    let mut split =\n+      timers.split_off(\u0026TimerKey(now, 0, TimerType::Once, false));\n     std::mem::swap(\u0026mut split, \u0026mut timers);\n     for TimerKey(_, id, timer_type, is_system_timer) in split {\n       if let TimerType::Repeat(interval) = timer_type {\n@@ -458,7 +475,7 @@ impl\u003cT: Clone\u003e WebTimers\u003cT\u003e {\n         }\n       }\n       if let Some(TimerKey(k, ..)) = timers.first() {\n-        self.sleep.change(*k);\n+        self.sleep.change(self.reactor.timer(*k));\n       }\n       return Poll::Pending;\n     }\n@@ -476,7 +493,7 @@ impl\u003cT: Clone\u003e WebTimers\u003cT\u003e {\n         timers.retain(|k| data.contains_key(\u0026k.1));\n       }\n       if let Some(TimerKey(k, ..)) = timers.first() {\n-        self.sleep.change(*k);\n+        self.sleep.change(self.reactor.timer(*k));\n       }\n     }\n \n@@ -613,9 +630,13 @@ impl HighResTimerLock {\n #[cfg(test)]\n mod tests {\n   use super::*;\n+  use crate::reactor_tokio::TokioReactor;\n   use rstest::rstest;\n+  use std::future::Future;\n   use std::future::poll_fn;\n \n+  type TestTimers = WebTimers\u003c(), TokioReactor\u003e;\n+\n   /// Miri is way too slow here on some of the larger tests.\n   const TEN_THOUSAND: u64 = if cfg!(miri) { 100 } else { 10_000 };\n \n@@ -628,7 +649,7 @@ mod tests {\n     runtime.block_on(f)\n   }\n \n-  async fn poll_all(timers: \u0026WebTimers\u003c()\u003e) -\u003e Vec\u003c(u64, ())\u003e {\n+  async fn poll_all(timers: \u0026TestTimers) -\u003e Vec\u003c(u64, ())\u003e {\n     timers.assert_consistent();\n     let len = timers.len();\n     let mut v = vec![];\n@@ -667,7 +688,7 @@ mod tests {\n     const TOMBSTONES: usize = 30; // \u003e COMPACTION_MINIMUM but \u003c ACTIVE_TIMERS\n     const CLEANUP_THRESHOLD: usize = 5; // Threshold to determine if compaction happened\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n \n       // Create mostly long-lived timers, with a few immediate ones\n       // The immediate timers ensure poll_timers returns non-empty output\n@@ -717,7 +738,7 @@ mod tests {\n   #[test]\n   fn test_timer() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       let _a = timers.queue_timer(1, ());\n \n       let v = poll_all(\u0026timers).await;\n@@ -728,7 +749,7 @@ mod tests {\n   #[test]\n   fn test_high_res_lock() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       assert!(!timers.high_res_timer_lock.is_locked());\n       let _a = timers.queue_timer(1, ());\n       assert!(timers.high_res_timer_lock.is_locked());\n@@ -743,7 +764,7 @@ mod tests {\n   #[test]\n   fn test_timer_cancel_1(#[values(0, 1, 2, 3)] which: u64) {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       for i in 0..4 {\n         let id = timers.queue_timer(i * 25, ());\n         if i == which {\n@@ -761,7 +782,7 @@ mod tests {\n   #[test]\n   fn test_timer_cancel_2(#[values(0, 1, 2)] which: u64) {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       for i in 0..4 {\n         let id = timers.queue_timer(i * 25, ());\n         if i == which || i == which + 1 {\n@@ -778,7 +799,7 @@ mod tests {\n   #[test]\n   fn test_timers_10_random() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       for i in 0..10 {\n         timers.queue_timer((i % 3) * 10, ());\n       }\n@@ -791,7 +812,7 @@ mod tests {\n   #[test]\n   fn test_timers_10_random_cancel() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       for i in 0..10 {\n         let id = timers.queue_timer((i % 3) * 10, ());\n         timers.cancel_timer(id);\n@@ -806,7 +827,7 @@ mod tests {\n   #[test]\n   fn test_timers_10_random_cancel_after(#[values(true, false)] reverse: bool) {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       let mut ids = vec![];\n       for i in 0..2 {\n         ids.push(timers.queue_timer((i % 3) * 10, ()));\n@@ -827,7 +848,7 @@ mod tests {\n   #[test]\n   fn test_timers_10() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       for _i in 0..10 {\n         timers.queue_timer(1, ());\n       }\n@@ -840,7 +861,7 @@ mod tests {\n   #[test]\n   fn test_timers_10_000_random() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       for i in 0..TEN_THOUSAND {\n         timers.queue_timer(i % 10, ());\n       }\n@@ -855,7 +876,7 @@ mod tests {\n   #[test]\n   fn test_timers_cancel_first() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       let mut ids = vec![];\n       for _ in 0..TEN_THOUSAND {\n         ids.push(timers.queue_timer(1, ()));\n@@ -874,7 +895,7 @@ mod tests {\n   #[test]\n   fn test_timers_10_000_cancel_most() {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       let mut ids = vec![];\n       for i in 0..TEN_THOUSAND {\n         ids.push(timers.queue_timer(i % 100, ()));\n@@ -896,7 +917,7 @@ mod tests {\n   #[test]\n   fn test_chaos(#[values(42, 99, 1000)] seed: u64) {\n     async_test(async {\n-      let timers = WebTimers::\u003c()\u003e::default();\n+      let timers = TestTimers::default();\n       fastrand::seed(seed);\n \n       let mut count = 0;\n",
      "is_error": false,
      "duration_ms": 54
    }
  ],
  "verified": false,
  "stats": {
    "api_calls": 2,
    "input_tokens": 19878,
    "output_tokens": 726,
    "elapsed_ms": 19035,
    "cost_usd": 0.070524
  },
  "created": "2026-02-18T12:59:02.454134+05:30"
}